# BERT for Question Answering

Description:

* Using 
  
  * [Pytorch-Lightning](https://pytorch-lightning.readthedocs.io/en/latest/)
  
  * [Huggingface transformers](https://huggingface.co/docs/transformers/index)
  
  * [MLflow](https://mlflow.org/)

* data: 
  
  * [cmrc2018 dataset](https://github.com/ymcui/cmrc2018)
  
  * [SQUAD dataset](https://rajpurkar.github.io/SQuAD-explorer/)

Run:

```bash
sh run.sh 
```

Reference:

* https://github.com/binnz/chinese-qa-with-bert
* [在机器问答任务上微调transformer模型](https://github.com/datawhalechina/learn-nlp-with-transformers/blob/main/docs/%E7%AF%87%E7%AB%A04-%E4%BD%BF%E7%94%A8Transformers%E8%A7%A3%E5%86%B3NLP%E4%BB%BB%E5%8A%A1/4.3-%E9%97%AE%E7%AD%94%E4%BB%BB%E5%8A%A1-%E6%8A%BD%E5%8F%96%E5%BC%8F%E9%97%AE%E7%AD%94.md)



Simple practice on BERT. Future improvements need to be done.
